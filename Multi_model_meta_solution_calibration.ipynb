{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaSfAQyxQgH0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import logging\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, KBinsDiscretizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from joblib import dump\n",
        "\n",
        "# Initialize logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def determine_best_bins(X, y, column, bins_range=(2, 10)):\n",
        "    \"\"\"\n",
        "    Determine the best number of bins for KBinsDiscretizer based on cross-validated model performance.\n",
        "    \"\"\"\n",
        "    best_bins = 2\n",
        "    best_score = -np.inf\n",
        "\n",
        "    for bins in range(bins_range[0], bins_range[1] + 1):\n",
        "        kbins = KBinsDiscretizer(n_bins=bins, encode='ordinal', strategy='quantile')\n",
        "        X_binned = kbins.fit_transform(X[[column]])\n",
        "        clf = LogisticRegression(max_iter=1000)\n",
        "        score = cross_val_score(clf, X_binned, y, cv=3, scoring=\"accuracy\").mean()\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_bins = bins\n",
        "\n",
        "    return best_bins\n",
        "\n",
        "\n",
        "def preprocess_column(data, col_name, y=None, train=True, kbins=None, scaler=None):\n",
        "    \"\"\"\n",
        "    Preprocess individual columns based on certain criteria.\n",
        "    \"\"\"\n",
        "    data_copy = data.copy()\n",
        "    if train:\n",
        "        if y is None:\n",
        "            raise ValueError(\"Target variable y must be provided during training phase.\")\n",
        "\n",
        "        # KBins discretization\n",
        "        best_bins = determine_best_bins(data, y, col_name)\n",
        "        kbins = KBinsDiscretizer(n_bins=best_bins, encode='ordinal', strategy='quantile')\n",
        "        data_copy[col_name] = kbins.fit_transform(data_copy[[col_name]])\n",
        "\n",
        "        # Scaling\n",
        "        if data_copy[col_name].mean() < data_copy[col_name].median() and data_copy[col_name].var() > 1:\n",
        "            scaler = StandardScaler()\n",
        "        elif data_copy[col_name].var() > 1:\n",
        "            scaler = MinMaxScaler()\n",
        "        if scaler:\n",
        "            data_copy[col_name] = scaler.fit_transform(data_copy[[col_name]])\n",
        "    else:\n",
        "        if kbins:\n",
        "            data_copy[col_name] = kbins.transform(data_copy[[col_name]])\n",
        "        if scaler:\n",
        "            data_copy[col_name] = scaler.transform(data_copy[[col_name]])\n",
        "\n",
        "    return data_copy, kbins, scaler\n"
      ],
      "metadata": {
        "id": "xZ3MxCJxpiZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(X_train, X_val, X_test, y_train):\n",
        "    \"\"\"\n",
        "    Preprocess datasets using column preprocessing logic.\n",
        "    \"\"\"\n",
        "    kbins_dict = {}\n",
        "    scaler_dict = {}\n",
        "\n",
        "    for col in X_train.columns:\n",
        "        X_train, kbins, scaler = preprocess_column(X_train, col, y_train, train=True)\n",
        "        kbins_dict[col] = kbins\n",
        "        scaler_dict[col] = scaler\n",
        "\n",
        "        X_val, _, _ = preprocess_column(X_val, col, train=False, kbins=kbins_dict[col], scaler=scaler_dict[col])\n",
        "        X_test, _, _ = preprocess_column(X_test, col, train=False, kbins=kbins_dict[col], scaler=scaler_dict[col])\n",
        "\n",
        "    return X_train, X_val, X_test\n"
      ],
      "metadata": {
        "id": "lYaqK4WlpkXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, param_grid, X, y, search_type=\"grid\", n_iter=10):\n",
        "    \"\"\"\n",
        "    Train model using GridSearch or RandomizedSearch.\n",
        "    \"\"\"\n",
        "    if search_type == \"grid\":\n",
        "        search = GridSearchCV(model, param_grid, cv=StratifiedKFold(n_splits=3))\n",
        "    elif search_type == \"random\":\n",
        "        search = RandomizedSearchCV(model, param_grid, cv=StratifiedKFold(n_splits=3), n_iter=n_iter)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown search_type: {search_type}\")\n",
        "\n",
        "    search.fit(X, y)\n",
        "    return search.best_estimator_\n",
        "\n",
        "\n",
        "def evaluate_model(model, X, y):\n",
        "    \"\"\"\n",
        "    Evaluate model performance.\n",
        "    \"\"\"\n",
        "    y_pred = model.predict(X)\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(y, y_pred),\n",
        "        'precision': precision_score(y, y_pred),\n",
        "        'recall': recall_score(y, y_pred),\n",
        "        'f1': f1_score(y, y_pred),\n",
        "        'roc_auc': roc_auc_score(y, y_pred)\n",
        "    }\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "cS6YRMqLpnfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "    # Preprocess data\n",
        "    X_train, X_val, X_test = preprocess_data(X_train, X_val, X_test, y_train)\n",
        "\n",
        "    # Model configurations\n",
        "    models_config = {\n",
        "        'Logistic Regression': {\n",
        "            'model': LogisticRegression(max_iter=1000),\n",
        "            'params': {'C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
        "            'search_type': \"grid\",\n",
        "            'n_iter': None\n",
        "        },\n",
        "        'Random Forest': {\n",
        "            'model': RandomForestClassifier(),\n",
        "            'params': {\n",
        "                'n_estimators': [100, 300, 500],\n",
        "                'max_depth': [None, 10, 20, 30],\n",
        "                'min_samples_split': [2, 5, 10],\n",
        "                'min_samples_leaf': [1, 2, 4],\n",
        "                'max_features': ['auto', 'sqrt']\n",
        "            },\n",
        "            'search_type': \"random\",\n",
        "            'n_iter': 10\n",
        "        },\n",
        "        'Gradient Boosting': {\n",
        "            'model': GradientBoostingClassifier(),\n",
        "            'params': {\n",
        "                'n_estimators': [100, 300, 500],\n",
        "                'learning_rate': [0.001, 0.01, 0.1],\n",
        "                'max_depth': [3, 5, 8],\n",
        "                'min_samples_split': [2, 5, 10],\n",
        "                'min_samples_leaf': [1, 2, 4]\n",
        "            },\n",
        "            'search_type': \"random\",\n",
        "            'n_iter': 10\n",
        "        },\n",
        "        'SVM': {\n",
        "            'model': SVC(probability=True),\n",
        "            'params': {\n",
        "                'C': [0.1, 1, 10],\n",
        "                'gamma': [1, 0.1, 0.01],\n",
        "                'kernel': ['linear', 'rbf']\n",
        "            },\n",
        "            'search_type': \"random\",\n",
        "            'n_iter': 6\n",
        "        },\n",
        "        'MLP': {\n",
        "            'model': MLPClassifier(max_iter=1000),\n",
        "            'params': {\n",
        "                'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50), (100,)],\n",
        "                'activation': ['tanh', 'relu'],\n",
        "                'solver': ['sgd', 'adam'],\n",
        "                'alpha': [0.0001, 0.05],\n",
        "                'learning_rate': ['constant', 'adaptive'],\n",
        "            },\n",
        "            'search_type': \"random\",\n",
        "            'n_iter': 10\n",
        "        },\n",
        "        'XGBoost': {\n",
        "            'model': XGBClassifier(),\n",
        "            'params': {\n",
        "                'n_estimators': [100, 300, 500],\n",
        "                'learning_rate': [0.001, 0.01, 0.1],\n",
        "                'max_depth': [3, 5, 8],\n",
        "                'min_child_weight': [1, 5, 10],\n",
        "                'subsample': [0.5, 0.7, 1.0],\n",
        "                'colsample_bytree': [0.5, 0.7, 1.0]\n",
        "            },\n",
        "            'search_type': \"random\",\n",
        "            'n_iter': 10\n",
        "        },\n",
        "        'CatBoost': {\n",
        "            'model': CatBoostClassifier(verbose=0),\n",
        "            'params': {\n",
        "                'iterations': [100, 300, 500],\n",
        "                'learning_rate': [0.001, 0.01, 0.1],\n",
        "                'depth': [4, 6, 8],\n",
        "                'l2_leaf_reg': [1, 3, 5, 7, 9]\n",
        "            },\n",
        "            'search_type': \"random\",\n",
        "            'n_iter': 10\n",
        "        }\n",
        "    }\n",
        "\n",
        "    #... rest of the main function ...\n",
        "    best_models = {}\n",
        "    model_scores = {}\n",
        "\n",
        "    for model_name, config in models_config.items():\n",
        "        logging.info(f\"Training {model_name}\")\n",
        "        best_model = train_model(\n",
        "            config['model'],\n",
        "            config['params'],\n",
        "            X_train, y_train,\n",
        "            search_type=config['search_type'],\n",
        "            n_iter=config['n_iter']\n",
        "        )\n",
        "        best_models[model_name] = best_model\n",
        "\n",
        "        val_metrics = evaluate_model(best_model, X_val, y_val)\n",
        "        model_scores[model_name] = val_metrics['f1']\n",
        "        logging.info(f\"{model_name} Validation Metrics: {val_metrics}\")\n",
        "\n",
        "    # Select best model based on F1-Score\n",
        "    best_model_name = max(model_scores, key=model_scores.get)\n",
        "    logging.info(f\"The best model is {best_model_name} with a Validation F1-Score of {model_scores[best_model_name]}\")\n",
        "\n",
        "    # Ensemble: Voting Classifiers\n",
        "    model_weights = list(model_scores.values())\n",
        "    hard_voting_clf = VotingClassifier(estimators=[(name, model) for name, model in best_models.items()], voting='hard')\n",
        "    hard_voting_clf.fit(X_train, y_train)\n",
        "    logging.info(f\"Hard Voting Classifier Validation ROC AUC: {evaluate_model(hard_voting_clf, X_val, y_val)['roc_auc']}\")\n",
        "\n",
        "    soft_voting_clf = VotingClassifier(estimators=[(name, model) for name, model in best_models.items()], voting='soft', weights=model_weights)\n",
        "    soft_voting_clf.fit(X_train, y_train)\n",
        "    logging.info(f\"Soft Voting Classifier Validation ROC AUC: {evaluate_model(soft_voting_clf, X_val, y_val)['roc_auc']}\")\n",
        "\n",
        "    # Calibrated Classifier for improved soft voting\n",
        "    calibrated_clf = CalibratedClassifierCV(soft_voting_clf, method='sigmoid', cv='prefit')\n",
        "    calibrated_clf.fit(X_val, y_val)\n",
        "    logging.info(f\"Calibrated Classifier Validation ROC AUC: {evaluate_model(calibrated_clf, X_val, y_val)['roc_auc']}\")\n",
        "\n",
        "    # Evaluate best model and ensemble models on test set\n",
        "    logging.info(f\"{best_model_name} Test Metrics: {evaluate_model(best_models[best_model_name], X_test, y_test)}\")\n",
        "    logging.info(f\"Hard Voting Classifier Test Metrics: {evaluate_model(hard_voting_clf, X_test, y_test)}\")\n",
        "    logging.info(f\"Soft Voting Classifier Test Metrics: {evaluate_model(soft_voting_clf, X_test, y_test)}\")\n",
        "    logging.info(f\"Calibrated Classifier Test Metrics: {evaluate_model(calibrated_clf, X_test, y_test)}\")\n",
        "\n",
        "    # Save the best model\n",
        "    dump(best_models[best_model_name], f\"{best_model_name}_best_model.pkl\")\n",
        "    logging.info(f\"{best_model_name} model saved to disk.\")\n"
      ],
      "metadata": {
        "id": "xDNh0vxVpqQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Assuming X_train, y_train, X_val, y_val, X_test, y_test are already defined\n",
        "    main(X_train, y_train, X_val, y_val, X_test, y_test)\n"
      ],
      "metadata": {
        "id": "EoQOyd0ep0Qs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}